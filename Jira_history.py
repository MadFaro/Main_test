
ffmpeg -i test.wav -filter:a loudnorm -ar 8000 -c:a pcm_s16le test2.wav
ffmpeg -i test.wav -filter:a loudnorm -ar 8000 -c:a pcm_s16le -b:a 128k -ac 2 test2.wav
ffmpeg -i test2.wav -af "volume=3.5" test3.wav
ffmpeg -i test3.wav -filter:a "atempo=0.95" test4.wav


ffmpeg -i input.wav -ar 16000 output.wav
ffmpeg -i output.wav -af "highpass=f=300, lowpass=f=3000" output1.wav
ffmpeg -i output1.wav -af "volume=1.5" output2.wav
ffmpeg -i output2.wav -af "equalizer=f=1000:width_type=h:w=200:g=5" output3.wav
ffmpeg -i output3.wav -af "crystalizer" output4.wav
=ЕСЛИОШИБКА((((@Agents($AH$2;$AI$2;I18;I68)/30)*22,5)/0,85)/I166;2)


Совместно с нашими коллегами из отдела аналитики, мы разработали и обучили ASR модель (Automatic Speech Recognition), используя мощный инструментарий Kaldi. Для достижения этой цели, мы провели тщательную подготовку данных, включая очистку аудиозаписей от шумов и нормализацию громкости. Дополнительно, мы разработали Python-скрипты, которые автоматизировали процесс обучения модели.

Итоговый рабочий процесс включает несколько этапов. Сначала скрипт на Python извлекает аудиозаписи из хранилища и проводит их сегментацию, учитывая определенные признаки. Далее, аудиоданные проходят дополнительную обработку, включая удаление шумов и нормализацию громкости.

ASR модель транскрибирует подготовленную запись в текст и сохраняет полученные данные в базе данных. Здесь информация дополняется метаданными, такими как тематика обращений, идентификация операторов и другие детали.

Параллельно с этим процессом, работают другие скрипты и модели, которые извлекают данные из БД и выполняют токенизацию и лемматизацию текста. Эти данные используются для решения конкретных задач, связанных с анализом качества обслуживания и контролем качества услуг, что дополнительно повышает эффективность и ценность данной системы.
